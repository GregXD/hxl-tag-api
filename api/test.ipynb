{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hdx.utilities.easy_logging import setup_logging\n",
    "from hdx.hdx_configuration import Configuration\n",
    "from hdx.data.dataset import Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import itertools \n",
    "import pickle\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from fastText import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import ngrams\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"try.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ruochen99/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopWords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fasttext_model = 'wiki.en.bin'\n",
    "fmodel = load_model(fasttext_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lower_cols(lst):\n",
    "    return [word.lower() for word in lst]\n",
    "\n",
    "\n",
    "def remove_chars(lst):\n",
    "\n",
    "    cleaned = [re.sub('\\s+', ' ', mystring).strip() for mystring in lst]\n",
    "    cleaned = [re.sub(r'[[^A-Za-z0-9\\s]+]', ' ', mystr) for mystr in cleaned]\n",
    "    cleaned = [mystr.replace('_', ' ') for mystr in cleaned]\n",
    "    return cleaned\n",
    "\n",
    "def clean_cols(data):\n",
    "    data = lower_cols(data)\n",
    "    data = remove_chars(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(pandas_dataset, df_target):\n",
    "    if (not pandas_dataset.empty):\n",
    "    \torganization = 'HDX'   #Replace if datasets contains organization\n",
    "    \theaders = list(pandas_dataset.columns.values)\n",
    "    \theaders = clean_cols(headers)\n",
    "    for i in range(len(headers)):\n",
    "        try:\n",
    "            dic = {'Header': headers[i], \n",
    "                   'Data': list(pandas_dataset.iloc[1:, i]), \n",
    "                   'Relative Column Position': (i+1) / len(pandas_dataset.columns), \n",
    "                   'Organization': organization,\n",
    "                   'Index': i}\n",
    "            df_target.loc[len(df_target)] = dic\n",
    "        except:\n",
    "            raise Exception(\"Error: arguments not matched\")\n",
    "\n",
    "    df_result = transform_vectorizers(df_target)\n",
    "    return df_result\n",
    "\n",
    "def transform_vectorizers(df_target):\n",
    "    cols = ['Header_embedding', 'Organization_embedded', 'BOW_counts', 'ngrams_counts']\n",
    "    df = pd.DataFrame(columns = cols)\n",
    "    long_string = []\n",
    "    for i in df_target['Data']:\n",
    "        result_by_tag = word_extract(i)\n",
    "        holder_list = ''.join(result_by_tag)\n",
    "        long_string.append(holder_list)\n",
    "    bag_vectorizer = CountVectorizer()\n",
    "    corpus = long_string\n",
    "    X_vecs_bag = bag_vectorizer.fit_transform(corpus)\n",
    "    df['BOW_counts'] = [item for item in X_vecs_bag.toarray()]\n",
    "    ngrams = generate_n_grams(df_target['Header'], 3)\n",
    "    ngrams_vectorizer = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False)\n",
    "    X_vec_grams = ngrams_vectorizer.fit_transform(ngrams)\n",
    "    df = df.iloc[:-2,:]\n",
    "    df['ngrams_counts'] = [item for item in X_vec_grams.toarray()]\n",
    "    df['Header_embedding'] = df_target['Header'].astype(str).apply(fmodel.get_sentence_vector)\n",
    "    df['Organization_embedded'] = df_target['Organization'].astype(str).apply(fmodel.get_sentence_vector)\n",
    "    cols = ['Header_embedding', 'Organization_embedded', 'BOW_counts', 'ngrams_counts']\n",
    "    df['features_combined'] = df[cols].values.tolist()\n",
    "    print(df['features_combined'][4])\n",
    "#     df['features_combined'] = df['features_combined'].apply(lambda x: np.concatenate(x, axis=None))\n",
    "    df['features_combined'] = df['features_combined'].apply(lambda x: [val for item in x for val in item])\n",
    "    df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_stop_words(data_lst):\n",
    "    #remove stopwords from the data including 'the', 'and' etc.\n",
    "    wordsFiltered = []\n",
    "    for w in data_lst:\n",
    "        if w not in stopWords:\n",
    "            wordsFiltered.append(w)\n",
    "    return wordsFiltered\n",
    "\n",
    "def word_extract(row):\n",
    "    ignore = ['nan']\n",
    "    no_white = [i.lstrip() for i in row if i not in ignore and not isinstance(i, float)]\n",
    "    cleaned_text = [w.lower() for w in no_white if w not in ignore]\n",
    "    return cleaned_text\n",
    "\n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and \\\n",
    "           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS \n",
    "\n",
    "from nltk import ngrams\n",
    "def generate_n_grams(data_lst, n):\n",
    "    # cleaned = remove_chars(list(data_lst))\n",
    "    # cleaned = clean_cols(cleaned)\n",
    "    cleaned = remove_stop_words(data_lst)\n",
    "    #make sure that n_grams 'refresh' when a new dataset is encountered!!!!   \n",
    "    return list(ngrams(cleaned, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([  2.47414857e-02,  -5.48960678e-02,   6.00527711e-02,\n",
      "        -7.03906417e-02,  -4.67367433e-02,  -7.32377395e-02,\n",
      "         8.01580697e-02,  -1.76433381e-02,  -1.93424094e-02,\n",
      "        -6.00202754e-02,  -2.23275833e-02,  -9.04171094e-02,\n",
      "         3.89071852e-02,  -6.47022873e-02,   6.15325430e-03,\n",
      "        -1.13157243e-01,  -5.76398000e-02,  -1.21198464e-02,\n",
      "        -2.22601520e-04,   8.93556774e-02,  -1.45886049e-01,\n",
      "        -6.35377783e-03,  -3.28403227e-02,   6.64590225e-02,\n",
      "         5.18646315e-02,   3.48556079e-02,   1.13761825e-02,\n",
      "        -8.12995732e-02,  -5.29367710e-04,   5.38800918e-02,\n",
      "        -8.24899152e-02,  -2.10784469e-02,  -5.52759394e-02,\n",
      "         2.61145970e-03,   1.64948087e-02,  -7.81606436e-02,\n",
      "        -1.30917365e-02,  -4.80476394e-02,   1.35536253e-01,\n",
      "         1.96997859e-02,  -1.78993661e-02,  -8.05781037e-02,\n",
      "         6.78841248e-02,   6.06602132e-02,   6.23246245e-02,\n",
      "         5.10848127e-02,  -4.83746938e-02,  -1.49348965e-02,\n",
      "        -5.13083972e-02,   1.30673414e-02,   2.31649913e-02,\n",
      "         2.48615220e-02,  -1.27439573e-03,  -5.77298030e-02,\n",
      "        -2.12483108e-02,   2.79839840e-02,  -2.26624142e-02,\n",
      "         1.32587105e-02,   6.36467189e-02,   1.01333089e-01,\n",
      "        -3.27546410e-02,   6.27804995e-02,  -1.94157436e-02,\n",
      "         7.08047068e-03,  -9.36526898e-03,  -1.06572419e-01,\n",
      "         6.48747310e-02,   4.28277999e-02,  -8.77830088e-02,\n",
      "         2.12155636e-02,   3.10776115e-04,   4.30678204e-02,\n",
      "        -2.51046065e-02,  -7.98661727e-03,  -8.05321112e-02,\n",
      "         1.14361480e-01,   8.50773379e-02,   6.95912773e-03,\n",
      "         4.38222773e-02,  -4.76965457e-02,   1.85634848e-02,\n",
      "         4.26306884e-04,  -6.22014664e-02,  -2.35113017e-02,\n",
      "        -1.12342492e-01,   4.11911123e-02,  -3.22934277e-02,\n",
      "         8.62993374e-02,   5.59360385e-02,  -1.22402154e-01,\n",
      "         3.01523004e-02,   3.09746303e-02,   2.10330822e-02,\n",
      "        -7.38793239e-02,   4.81798388e-02,   4.98782322e-02,\n",
      "         5.86418733e-02,   6.82072192e-02,  -3.58522609e-02,\n",
      "         1.35134337e-02,  -2.97824852e-02,  -5.20714298e-02,\n",
      "         1.38196014e-02,  -8.52699485e-03,  -3.79024097e-03,\n",
      "        -2.52457485e-02,   1.79372635e-02,  -1.50118098e-01,\n",
      "        -3.94861698e-02,  -7.91224167e-02,  -9.63138358e-04,\n",
      "        -3.35919484e-02,   4.13568430e-02,   4.12109978e-02,\n",
      "         8.91977642e-03,  -5.19761443e-02,  -3.68512585e-03,\n",
      "         1.57204550e-02,   6.06369274e-03,   3.96431573e-02,\n",
      "         1.32645473e-01,  -4.52026539e-02,   4.98285443e-02,\n",
      "         5.95503673e-02,   7.81771690e-02,  -2.16277428e-02,\n",
      "         1.61143448e-02,   8.82875398e-02,   6.48032799e-02,\n",
      "         2.79713944e-02,  -5.82585223e-02,   3.61938924e-02,\n",
      "         3.99680436e-02,  -3.45040136e-03,   8.97111893e-02,\n",
      "         1.47490099e-03,  -5.31319752e-02,  -1.56918429e-02,\n",
      "         1.93107482e-02,   1.58792987e-01,  -2.77579594e-02,\n",
      "         6.64267913e-02,  -5.77904694e-02,   4.61558849e-02,\n",
      "         2.04766080e-01,   9.30335820e-02,   4.00177911e-02,\n",
      "         9.39305499e-03,  -5.17381355e-02,   5.57722487e-02,\n",
      "         1.66249737e-01,  -2.62043215e-02,  -4.84389775e-02,\n",
      "         3.16141509e-02,  -7.59151280e-02,  -4.83989716e-02,\n",
      "        -7.47172460e-02,  -2.36221999e-02,  -2.22973190e-02,\n",
      "         5.11678047e-02,   2.16477234e-02,   4.43444848e-02,\n",
      "         3.28496397e-02,   2.03308929e-02,   9.45762545e-02,\n",
      "         6.48827329e-02,   1.05092034e-01,   3.85303460e-02,\n",
      "         4.53885719e-02,  -2.96226572e-02,  -2.44004223e-02,\n",
      "         7.25826547e-02,  -6.51624799e-02,  -3.76261175e-02,\n",
      "         2.65833316e-03,   1.45808086e-02,  -2.67458754e-03,\n",
      "         1.11773446e-01,   5.82582876e-03,  -2.33294368e-02,\n",
      "         4.80807312e-02,  -2.80569457e-02,   6.69470504e-02,\n",
      "        -3.51943672e-02,   8.47514197e-02,   8.20398889e-03,\n",
      "         3.01817171e-02,  -8.57677683e-02,  -1.24454927e-02,\n",
      "        -3.89393643e-02,  -9.10794083e-03,  -6.66635185e-02,\n",
      "         1.83281563e-02,  -5.28777670e-03,   6.52650371e-02,\n",
      "         4.61969748e-02,  -2.97544487e-02,   9.76950377e-02,\n",
      "        -4.51074261e-03,  -9.53012258e-02,   4.51411121e-03,\n",
      "         1.37615148e-02,   7.32065067e-02,   2.14226563e-02,\n",
      "        -3.49347815e-02,  -1.90617470e-03,  -1.80168115e-02,\n",
      "        -3.80341895e-02,   6.77089542e-02,   4.97945845e-02,\n",
      "         2.16818019e-03,  -6.90749884e-02,  -4.97643761e-02,\n",
      "         2.36687306e-02,  -2.39268485e-02,   1.21849207e-02,\n",
      "         3.85876652e-03,  -1.26230568e-01,   1.87311950e-03,\n",
      "        -1.10514024e-02,   3.05897389e-02,   6.49456233e-02,\n",
      "        -4.51223552e-02,   9.87307280e-02,   5.13329357e-02,\n",
      "        -1.11015332e-04,   7.05898134e-03,   5.44044524e-02,\n",
      "         1.13012001e-01,   4.31637140e-03,   8.53467211e-02,\n",
      "        -2.26475131e-02,  -4.70323414e-02,   5.49938157e-02,\n",
      "        -9.40061882e-02,  -7.48837590e-02,   4.14925367e-02,\n",
      "        -1.19478621e-01,  -1.01670800e-02,  -5.53717650e-02,\n",
      "        -1.26796201e-01,   4.50632721e-02,   2.40388364e-02,\n",
      "         5.82952909e-02,  -2.60352995e-02,  -5.24708964e-02,\n",
      "         6.32656589e-02,   5.71930818e-02,  -8.07432830e-03,\n",
      "         4.88945954e-02,   5.56332013e-03,  -4.94627189e-03,\n",
      "         2.50408170e-03,  -3.97659466e-02,  -4.36273217e-02,\n",
      "         5.41643687e-02,   1.97472006e-01,  -8.97229537e-02,\n",
      "         1.16855847e-02,  -2.13961117e-02,  -4.96195406e-02,\n",
      "         3.37200947e-02,  -4.22303155e-02,   6.68457011e-03,\n",
      "        -7.44477734e-02,   5.58876607e-04,   2.26458535e-02,\n",
      "         5.83366454e-02,   4.44333553e-02,   5.67873940e-02,\n",
      "        -4.49334383e-02,  -5.40819839e-02,   8.65192190e-02,\n",
      "        -6.64058700e-02,  -1.06202722e-01,  -3.40572074e-02,\n",
      "        -4.39978875e-02,   6.51412010e-02,   8.12922269e-02,\n",
      "        -1.02620879e-02,  -1.00916252e-02,   3.93266268e-02,\n",
      "        -7.56478636e-03,   2.18048487e-02,  -6.08912446e-02,\n",
      "         6.52336190e-03,   1.57410260e-02,  -8.88164714e-02,\n",
      "        -6.09146394e-02,   1.43490173e-02,  -6.10825000e-03,\n",
      "         2.67195236e-03,  -2.44013295e-02,   1.05742425e-01,\n",
      "        -3.20753045e-02,  -2.26362189e-03,   8.98508169e-03,\n",
      "        -2.75110430e-03,   1.36788161e-02,  -4.80969772e-02], dtype=float32), array([ 0.01229391, -0.0148763 , -0.08583111,  0.06938633, -0.00745857,\n",
      "       -0.08445334,  0.03858099, -0.08929422, -0.01070416, -0.03540026,\n",
      "       -0.02157565,  0.03336642,  0.00784011, -0.01582014,  0.0359115 ,\n",
      "       -0.02503123, -0.02712249, -0.00929648, -0.02198123,  0.03642303,\n",
      "       -0.11120522, -0.02952013, -0.08265695,  0.00506991, -0.13782315,\n",
      "       -0.07748032, -0.09081068,  0.10201493,  0.02548006,  0.07723886,\n",
      "        0.00501773,  0.06937136,  0.02503015,  0.04948284,  0.01055827,\n",
      "       -0.01777411, -0.03173355, -0.0245574 ,  0.04043822, -0.11149389,\n",
      "       -0.01125182, -0.01346513,  0.01169896,  0.02190053,  0.03995641,\n",
      "        0.02503541, -0.02402888,  0.0415897 ,  0.10185561,  0.09473187,\n",
      "       -0.03390104, -0.07141189,  0.00378888,  0.071554  , -0.00266793,\n",
      "        0.08361288,  0.04397549, -0.02039438,  0.02537349,  0.01807339,\n",
      "        0.04296357,  0.08750353,  0.02633218,  0.0007702 ,  0.06670129,\n",
      "       -0.102774  ,  0.0005112 ,  0.0317003 , -0.01802608, -0.03986124,\n",
      "        0.04099736,  0.00924306,  0.10179862,  0.05594258, -0.05368501,\n",
      "        0.04681642,  0.02281571,  0.0818748 , -0.04837267, -0.10587097,\n",
      "       -0.032266  ,  0.01732785,  0.06328577,  0.03692089,  0.01435082,\n",
      "       -0.00591428,  0.00559488, -0.01440452,  0.05010993,  0.12033194,\n",
      "       -0.11259792, -0.01465159, -0.00081168,  0.02160846, -0.00760153,\n",
      "       -0.02049549,  0.00671224,  0.00119536, -0.04219047, -0.02325646,\n",
      "       -0.04468441,  0.05940706, -0.05979708,  0.05153925, -0.02554005,\n",
      "       -0.01120795, -0.04160876,  0.0832679 ,  0.04317919, -0.02226994,\n",
      "       -0.08902153,  0.03189318,  0.04835468, -0.09524977, -0.03324173,\n",
      "        0.05658479, -0.04453599,  0.04458063, -0.02959032,  0.02603983,\n",
      "       -0.00486257, -0.04057513,  0.0410496 , -0.0162735 , -0.04410274,\n",
      "        0.07176649,  0.00573646, -0.05286517,  0.00159176,  0.00349943,\n",
      "       -0.02824203,  0.02839637,  0.05647684,  0.03814538,  0.02028391,\n",
      "        0.01572838, -0.01363856, -0.01881412, -0.01748966, -0.01860685,\n",
      "       -0.08647155,  0.05479406,  0.06842935,  0.03231456,  0.10815812,\n",
      "        0.04469447, -0.07044988,  0.03172704, -0.02034163,  0.06495843,\n",
      "        0.1352649 , -0.02292518, -0.04615266,  0.05628477, -0.01044265,\n",
      "        0.01986491,  0.07046713, -0.01574454,  0.0262182 , -0.10503563,\n",
      "        0.05071929,  0.06783099,  0.12492291, -0.02199819,  0.0557862 ,\n",
      "        0.02332138,  0.01782172, -0.0631953 ,  0.04038328,  0.00438586,\n",
      "       -0.04481405, -0.0499656 , -0.18267433, -0.03963819, -0.01346119,\n",
      "       -0.00970167, -0.05769606,  0.05959142,  0.07820284, -0.05228788,\n",
      "        0.01883752, -0.01491158, -0.12095478,  0.02093587, -0.01329634,\n",
      "        0.08287512,  0.08270933, -0.1063417 ,  0.02802426,  0.07816399,\n",
      "        0.10336547, -0.00672247,  0.04935135, -0.00878526,  0.10992221,\n",
      "        0.11234581,  0.0268847 ,  0.07330664,  0.06733193, -0.02192812,\n",
      "        0.07034532, -0.05631187, -0.05805926,  0.00470239,  0.03668553,\n",
      "       -0.05266852,  0.04639139, -0.01292864, -0.00053369, -0.063965  ,\n",
      "        0.06992191, -0.00393768,  0.00827438, -0.07130131,  0.07300828,\n",
      "       -0.08067987,  0.01852495, -0.11620652, -0.01245062, -0.04290383,\n",
      "        0.11775009,  0.06120261, -0.0828437 , -0.0812983 ,  0.06588785,\n",
      "       -0.03383784,  0.05433045,  0.0014439 ,  0.08735859, -0.07162345,\n",
      "        0.05010993, -0.03052881, -0.08992573,  0.08208401,  0.03446177,\n",
      "        0.02030283, -0.00202305, -0.00105735, -0.01289176,  0.03119492,\n",
      "        0.02555659, -0.05714786, -0.15269136, -0.04853456, -0.00363243,\n",
      "       -0.00290068, -0.02563342, -0.00401887, -0.09735005, -0.00112166,\n",
      "        0.06790877, -0.00324873,  0.10392494, -0.02132839,  0.07013626,\n",
      "        0.12960632,  0.06283547,  0.06250474,  0.06692615,  0.06135711,\n",
      "       -0.0618395 ,  0.1140167 , -0.03621694, -0.04361176,  0.00195138,\n",
      "        0.01552971,  0.1128094 , -0.03038835,  0.0580221 , -0.00553572,\n",
      "        0.03591465,  0.05115182, -0.06359155, -0.07923453,  0.05088811,\n",
      "       -0.05673026,  0.01764453, -0.03815878,  0.00277542, -0.04703024,\n",
      "        0.00888136,  0.09760068, -0.01131522,  0.06730974,  0.04996751,\n",
      "        0.07693556, -0.04515637, -0.02175421,  0.06524988, -0.07343689,\n",
      "        0.04743475, -0.05774866,  0.05650435,  0.04945228, -0.03553741,\n",
      "        0.07206362, -0.02562725, -0.02545234, -0.01327771,  0.16735558], dtype=float32), array([ 0,  0,  0,  0,  0,  0,  1,  0,  0,  3,  1,  1,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  1,  0,  0,  0,  0,\n",
      "        0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  3,  0,  1,  0,  0,  0,\n",
      "        0, 10,  0,  0,  0,  1,  1,  3,  0,  0,  0,  0,  0,  0,  2,  0,  0,\n",
      "        0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  1,  2,  0,  1,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  1,  0,  0,  0,\n",
      "        0,  0,  0,  1,  1,  1,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  1,  1,  1,  1,  1,  1,  0,  0,  0,  2,  1,  0,  0,  1,  0,\n",
      "        0,  0,  0,  1,  1,  1,  0,  1, 12,  1,  1,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "        2,  1,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  1,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  0,\n",
      "        2,  0,  0, 54,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  1,  0,  0,  0,  0,  0,\n",
      "        0,  2,  0,  1,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  1,  1,  1,  1,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,\n",
      "        0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  5,  1,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0], dtype=int64), array([1, 1, 0, 0, 1, 0, 0], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "processed_dataset = preprocess(df, \n",
    "                pd.DataFrame(columns=['Header','Data','Relative Column Position','Organization','Index']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.0 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.19.0 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "model = pickle.load(open(\"model.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset['features_combined'] = processed_dataset['features_combined'].apply(lambda x: [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(processed_dataset['features_combined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-35d2df848d75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features_combined'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    947\u001b[0m         \"\"\"\n\u001b[1;32m    948\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coefs_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mdecision\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m         \"\"\"\n\u001b[0;32m--> 660\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;31m# Make sure self.hidden_layer_sizes is a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    431\u001b[0m                                       force_all_finite)\n\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "model.predict(processed_dataset['features_combined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
