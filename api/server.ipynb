{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from flask import Flask, redirect, request, render_template, url_for, send_from_directory, make_response\n",
    "from werkzeug.wrappers import Request, Response\n",
    "from werkzeug.serving import run_simple\n",
    "from jsonrpc import JSONRPCResponseManager, dispatcher\n",
    "import os\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from werkzeug.utils import secure_filename\n",
    "import pickle\n",
    "import re\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from fastText import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from flask_cors import CORS\n",
    "from nltk import ngrams\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.20.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ruochen99/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopWords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Install fastText by doing:<br>\n",
    "#git clone https://github.com/facebookresearch/fastText.git<br>\n",
    "#cd fastText<br>\n",
    "#pip install .<br>\n",
    "#'wiki.en.bin' needs to be in the same directory as server.py (can be downloaded from <br>\n",
    "#https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.en.zip)<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fasttext_model = 'wiki.en.bin'\n",
    "fmodel = load_model(fasttext_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UPLOAD_FOLDER = '\\datasets'\n",
    "ALLOWED_EXTENSIONS_CSV = set(['csv'])\n",
    "ALLOWED_EXTENSIONS_JSON = set(['json'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# app = Flask(__name__)\n",
    "# # CORS(app)\n",
    "# app.config['UPLOAD_FOLDER'] = os.path.join(app.instance_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lower_cols(lst):\n",
    "    #convert data to lowercases\n",
    "    #QUESTION: will I miss any important information? \n",
    "    return [word.lower() for word in lst if isinstance(word,str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_chars(lst):\n",
    "    #remove punctuation characters such as \",\", \"(\", \")\", \"\"\", \":\", \"/\", and \".\"\n",
    "    #NOTE: PRESERVES WHITE SPACE.\n",
    "    #QUESTION: any other characters we should be aware of? Is this a good idea? I'm inspecting each word individually.\n",
    "    #Any potential pitfalls? \n",
    "    cleaned = [re.sub('\\s+', ' ', mystring).strip() for mystring in lst]\n",
    "    cleaned = [re.sub(r'[[^A-Za-z0-9\\s]+]', ' ', mystr) for mystr in cleaned]\n",
    "    cleaned = [mystr.replace('_', ' ') for mystr in cleaned]\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_cols(data):\n",
    "    data = lower_cols(data)\n",
    "    data = remove_chars(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_empty_cols(df):\n",
    "    empty_cols = []\n",
    "    for i in df.columns.values:\n",
    "        if (len(df[i].dropna()) == 0):\n",
    "            df.at[2,i] = 1\n",
    "            empty_cols.append(df.columns.get_loc(i))\n",
    "    return df, empty_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(pandas_dataset, df_target):\n",
    "    if (not pandas_dataset.empty):\n",
    "        organization = 'HDX'   #Replace if datasets contains organization\n",
    "        pandas_dataset.dropna(how = 'all', inplace = True)\n",
    "        pandas_dataset, empty_cols = fill_empty_cols(pandas_dataset)\n",
    "        print(empty_cols)\n",
    "#         pandas_dataset.dropna(axis=1, how = 'all', subset=range(1,len(pandas_dataset)), inplace = True)\n",
    "        headers = list(pandas_dataset.columns.values)        \n",
    "        headers = clean_cols(headers)\n",
    "    for i in range(len(headers)):\n",
    "        try:\n",
    "            dic = {'Header': headers[i], \n",
    "                   'Data': list(pandas_dataset.iloc[1:, i]), \n",
    "                   'Relative Column Position': (i+1) / len(pandas_dataset.columns), \n",
    "                   'Organization': organization,\n",
    "                   'Index': i}\n",
    "            df_target.loc[len(df_target)] = dic\n",
    "        except:\n",
    "            raise Exception(\"Error: arguments not matched\")\n",
    "    df_result = transform_vectorizers(df_target)\n",
    "    return df_target, df_result, empty_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_vectorizers(df_target):\n",
    "    number_of_data_point_to_vectorize = 7\n",
    "    cols = ['Header_embedding', 'Organization_embedded', 'features_combined']\n",
    "    df = pd.DataFrame(columns = cols)\n",
    "    df_target, number_of_data_point_to_vectorize = embedded_datapoints(df_target, 7)\n",
    "    df['data_combined'] = df_target.loc[:, 'embedded_datapoint0': 'embedded_datapoint' \n",
    "                                                           + str(number_of_data_point_to_vectorize-1)].values.tolist()\n",
    "    df['data_combined'] = df['data_combined'].apply(lambda x: [val for item in x for val in item])\n",
    "    df['Header_embedding'] = df_target['Header'].astype(str).apply(fmodel.get_sentence_vector)\n",
    "    df['Organization_embedded'] = df_target['Organization'].astype(str).apply(fmodel.get_sentence_vector)\n",
    "    cols = ['Header_embedding', 'Organization_embedded', 'data_combined']\n",
    "    df['features_combined'] = df[cols].values.tolist()\n",
    "    df['features_combined'] = df['features_combined'].apply(lambda x: [val for item in x for val in item])\n",
    "    diff = 2700 - len(df['features_combined'][0])\n",
    "    for i in range(len(df)):\n",
    "        for j in range(diff):\n",
    "            df['features_combined'][i].append(0)\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def separate_words(series): \n",
    "    #each series is a long string that contains all the data\n",
    "    lst = []\n",
    "    cleanlist = [str(x) for x in series if str(x) != 'nan']\n",
    "    for i in cleanlist:\n",
    "        lst = re.split(r\"\\W+\", i)\n",
    "        lst.extend(list(filter(None, lst)))\n",
    "    return lst\n",
    "    \n",
    "def vectorize_n_datapoints(df, number_of_datapoints_to_vectorize = 7):\n",
    "#     print(df['Data'].head())\n",
    "#     print(df['Data'].iloc[0])\n",
    "#     for i in range(len(df['Data'])):\n",
    "#         df['Data_separated'].iloc[0] = separate_words(df['Data'].iloc[0])\n",
    "    df['Data_separated'] = df['Data'].apply(separate_words)\n",
    "    if (number_of_datapoints_to_vectorize > len(df['Data_separated'][0])):\n",
    "        number_of_datapoints_to_vectorize = len(df['Data_separated'][0])\n",
    "    for i in range(number_of_datapoints_to_vectorize):\n",
    "        df['datapoint' + str(i)] = df['Data_separated'].str[i]\n",
    "    return df, number_of_datapoints_to_vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedded_datapoints(df, number_of_data_point_to_vectorize=7):\n",
    "    df, number_of_data_point_to_vectorize = vectorize_n_datapoints(df)\n",
    "    for i in range(number_of_data_point_to_vectorize):\n",
    "        \n",
    "        df['embedded_datapoint' + str(i)] = df['datapoint' + str(i)].map(lambda x: fmodel.get_sentence_vector(str(x)))\n",
    "    return df, number_of_data_point_to_vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_stop_words(data_lst):\n",
    "    #remove stopwords from the data including 'the', 'and' etc.\n",
    "    wordsFiltered = []\n",
    "    for w in data_lst:\n",
    "        if w not in stopWords:\n",
    "            wordsFiltered.append(w)\n",
    "    return wordsFiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_extract(row):\n",
    "    ignore = ['nan']\n",
    "    no_white = [i.lstrip() for i in row if i not in ignore and not (isinstance(i, float) or isinstance(i,int))]\n",
    "    cleaned_text = [w.lower() for w in no_white if w not in ignore]\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def allowed_file_csv(filename):\n",
    "    return '.' in filename and \\\n",
    "           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS_CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def allowed_file_json(filename):\n",
    "    return '.' in filename and \\\n",
    "            filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS_JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_n_grams(data_lst, n):\n",
    "    # cleaned = remove_chars(list(data_lst))\n",
    "    # cleaned = clean_cols(cleaned)\n",
    "    cleaned = remove_stop_words(data_lst)\n",
    "    #make sure that n_grams 'refresh' when a new dataset is encountered!!!!   \n",
    "    return list(ngrams(cleaned, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dataset = pd.read_csv('test_files/fts_incoming_funding_tgo.csv', encoding = \"ISO-8859-1\", na_values=['nan',' nan'])\n",
    "input_headers = input_dataset.columns.values\n",
    "# input_dataset = input_dataset.rename(columns=input_dataset.iloc[0]).drop(input_dataset.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>budgetYear</th>\n",
       "      <th>description</th>\n",
       "      <th>amountUSD</th>\n",
       "      <th>srcOrganization</th>\n",
       "      <th>srcOrganizationTypes</th>\n",
       "      <th>srcLocations</th>\n",
       "      <th>srcUsageYearStart</th>\n",
       "      <th>srcUsageYearEnd</th>\n",
       "      <th>destPlan</th>\n",
       "      <th>...</th>\n",
       "      <th>firstReportedDate</th>\n",
       "      <th>decisionDate</th>\n",
       "      <th>keywords</th>\n",
       "      <th>originalAmount</th>\n",
       "      <th>originalCurrency</th>\n",
       "      <th>exchangeRate</th>\n",
       "      <th>id</th>\n",
       "      <th>refCode</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>updatedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#date</td>\n",
       "      <td>#date+year+budget</td>\n",
       "      <td>#description+notes</td>\n",
       "      <td>#value+funding+total+usd</td>\n",
       "      <td>#org+name+funder</td>\n",
       "      <td>#org+type+funder+list</td>\n",
       "      <td>#country+iso3+funder+list</td>\n",
       "      <td>#date+year+start+funder</td>\n",
       "      <td>#date+year+end+funder</td>\n",
       "      <td>#activity+appeal+name+impl</td>\n",
       "      <td>...</td>\n",
       "      <td>#date+reported</td>\n",
       "      <td>#date+decision</td>\n",
       "      <td>#description+keywords</td>\n",
       "      <td>#value+funding+total</td>\n",
       "      <td>#value+funding+total+currency</td>\n",
       "      <td>#financial+fx</td>\n",
       "      <td>#activity+id+fts_internal</td>\n",
       "      <td>#activity+code</td>\n",
       "      <td>#date+created</td>\n",
       "      <td>#date+updated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-03-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fall Army Worm / Lutte contre la chenille legi...</td>\n",
       "      <td>1000000</td>\n",
       "      <td>African Development Bank</td>\n",
       "      <td>Inter-governmental</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-03-14</td>\n",
       "      <td>2019-03-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>188251</td>\n",
       "      <td>OSRO/TOG/901/ADB</td>\n",
       "      <td>2019-03-15</td>\n",
       "      <td>2019-03-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Towards a Universal Access of Vulnerable Girls...</td>\n",
       "      <td>0</td>\n",
       "      <td>Education Above All Foundation</td>\n",
       "      <td>Private organization/foundation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-05-20</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>Multiyear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175161</td>\n",
       "      <td>EAA/EAC/CT/16/2016</td>\n",
       "      <td>2018-05-23</td>\n",
       "      <td>2018-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Towards a Universal Access of Vulnerable Girls...</td>\n",
       "      <td>183965</td>\n",
       "      <td>Education Above All Foundation</td>\n",
       "      <td>Private organization/foundation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-05-20</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>Multiyear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175165</td>\n",
       "      <td>EAA/EAC/CT/16/2016</td>\n",
       "      <td>2018-05-23</td>\n",
       "      <td>2018-05-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date         budgetYear  \\\n",
       "0       #date  #date+year+budget   \n",
       "1  2019-03-08                NaN   \n",
       "2  2017-01-31                NaN   \n",
       "3  2017-01-31                NaN   \n",
       "\n",
       "                                         description  \\\n",
       "0                                 #description+notes   \n",
       "1  Fall Army Worm / Lutte contre la chenille legi...   \n",
       "2  Towards a Universal Access of Vulnerable Girls...   \n",
       "3  Towards a Universal Access of Vulnerable Girls...   \n",
       "\n",
       "                  amountUSD                 srcOrganization  \\\n",
       "0  #value+funding+total+usd                #org+name+funder   \n",
       "1                   1000000        African Development Bank   \n",
       "2                         0  Education Above All Foundation   \n",
       "3                    183965  Education Above All Foundation   \n",
       "\n",
       "              srcOrganizationTypes               srcLocations  \\\n",
       "0            #org+type+funder+list  #country+iso3+funder+list   \n",
       "1               Inter-governmental                        NaN   \n",
       "2  Private organization/foundation                        NaN   \n",
       "3  Private organization/foundation                        NaN   \n",
       "\n",
       "         srcUsageYearStart        srcUsageYearEnd                    destPlan  \\\n",
       "0  #date+year+start+funder  #date+year+end+funder  #activity+appeal+name+impl   \n",
       "1                     2019                   2019                         NaN   \n",
       "2                     2017                   2017                         NaN   \n",
       "3                     2017                   2017                         NaN   \n",
       "\n",
       "       ...       firstReportedDate    decisionDate               keywords  \\\n",
       "0      ...          #date+reported  #date+decision  #description+keywords   \n",
       "1      ...              2019-03-14      2019-03-08                    NaN   \n",
       "2      ...              2018-05-20      2017-01-31              Multiyear   \n",
       "3      ...              2018-05-20      2017-01-31              Multiyear   \n",
       "\n",
       "         originalAmount               originalCurrency   exchangeRate  \\\n",
       "0  #value+funding+total  #value+funding+total+currency  #financial+fx   \n",
       "1                   NaN                            USD            NaN   \n",
       "2                   NaN                            NaN            NaN   \n",
       "3                   NaN                            NaN            NaN   \n",
       "\n",
       "                          id             refCode      createdAt      updatedAt  \n",
       "0  #activity+id+fts_internal      #activity+code  #date+created  #date+updated  \n",
       "1                     188251    OSRO/TOG/901/ADB     2019-03-15     2019-03-18  \n",
       "2                     175161  EAA/EAC/CT/16/2016     2018-05-23     2018-05-23  \n",
       "3                     175165  EAA/EAC/CT/16/2016     2018-05-23     2018-05-23  \n",
       "\n",
       "[4 rows x 35 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# process the untagged dataset\n",
    "raw, processed_dataset, empty_cols = preprocess(input_dataset, \n",
    "                               pd.DataFrame(columns=['Header','Data','Relative Column Position','Organization','Index']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Header_embedding</th>\n",
       "      <th>Organization_embedded</th>\n",
       "      <th>features_combined</th>\n",
       "      <th>data_combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.00187157, -0.0188091, -0.00182546, -0.03487...</td>\n",
       "      <td>[0.0122939, -0.0148763, -0.0858311, 0.0693863,...</td>\n",
       "      <td>[0.00187157, -0.0188091, -0.00182546, -0.03487...</td>\n",
       "      <td>[0.061183, -0.108557, -0.0215283, -0.0257585, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.0577098, 0.0106014, 0.076496, 0.0175093, 0...</td>\n",
       "      <td>[0.0122939, -0.0148763, -0.0858311, 0.0693863,...</td>\n",
       "      <td>[-0.0577098, 0.0106014, 0.076496, 0.0175093, 0...</td>\n",
       "      <td>[0.0566073, 0.0195136, -0.00766985, -0.0078007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.0117924, 0.0334399, -0.0723287, 0.00917512...</td>\n",
       "      <td>[0.0122939, -0.0148763, -0.0858311, 0.0693863,...</td>\n",
       "      <td>[-0.0117924, 0.0334399, -0.0723287, 0.00917512...</td>\n",
       "      <td>[-0.0609063, -0.0311797, -0.031652, 0.08444, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.0607706, -0.0288627, -0.0202762, -0.003495...</td>\n",
       "      <td>[0.0122939, -0.0148763, -0.0858311, 0.0693863,...</td>\n",
       "      <td>[-0.0607706, -0.0288627, -0.0202762, -0.003495...</td>\n",
       "      <td>[0.028683, 0.0406691, -0.0608491, -0.00199248,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.0170964, -0.0967856, -0.00234281, 0.035446...</td>\n",
       "      <td>[0.0122939, -0.0148763, -0.0858311, 0.0693863,...</td>\n",
       "      <td>[-0.0170964, -0.0967856, -0.00234281, 0.035446...</td>\n",
       "      <td>[0.0490048, -0.0140489, -0.0217238, 0.0548013,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Header_embedding  \\\n",
       "0  [0.00187157, -0.0188091, -0.00182546, -0.03487...   \n",
       "1  [-0.0577098, 0.0106014, 0.076496, 0.0175093, 0...   \n",
       "2  [-0.0117924, 0.0334399, -0.0723287, 0.00917512...   \n",
       "3  [-0.0607706, -0.0288627, -0.0202762, -0.003495...   \n",
       "4  [-0.0170964, -0.0967856, -0.00234281, 0.035446...   \n",
       "\n",
       "                               Organization_embedded  \\\n",
       "0  [0.0122939, -0.0148763, -0.0858311, 0.0693863,...   \n",
       "1  [0.0122939, -0.0148763, -0.0858311, 0.0693863,...   \n",
       "2  [0.0122939, -0.0148763, -0.0858311, 0.0693863,...   \n",
       "3  [0.0122939, -0.0148763, -0.0858311, 0.0693863,...   \n",
       "4  [0.0122939, -0.0148763, -0.0858311, 0.0693863,...   \n",
       "\n",
       "                                   features_combined  \\\n",
       "0  [0.00187157, -0.0188091, -0.00182546, -0.03487...   \n",
       "1  [-0.0577098, 0.0106014, 0.076496, 0.0175093, 0...   \n",
       "2  [-0.0117924, 0.0334399, -0.0723287, 0.00917512...   \n",
       "3  [-0.0607706, -0.0288627, -0.0202762, -0.003495...   \n",
       "4  [-0.0170964, -0.0967856, -0.00234281, 0.035446...   \n",
       "\n",
       "                                       data_combined  \n",
       "0  [0.061183, -0.108557, -0.0215283, -0.0257585, ...  \n",
       "1  [0.0566073, 0.0195136, -0.00766985, -0.0078007...  \n",
       "2  [-0.0609063, -0.0311797, -0.031652, 0.08444, 0...  \n",
       "3  [0.028683, 0.0406691, -0.0608491, -0.00199248,...  \n",
       "4  [0.0490048, -0.0140489, -0.0217238, 0.0548013,...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "na = []\n",
    "for i in range(len(processed_dataset)):\n",
    "    na.append(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tag_predicted(clf, X_test, series, threshold):\n",
    "    #True if tag should be left blank\n",
    "    if (not isinstance(X_test, np.ndarray)):\n",
    "        X_test = X_test.values.tolist()\n",
    "    probs = clf.predict_proba(X_test)\n",
    "    values = []\n",
    "    for i in range(len(X_test)):\n",
    "        max_arg = probs[i].argsort()[-1]\n",
    "        top_suggested_tag = clf.classes_[max_arg]\n",
    "        prob = np.take(probs[i], max_arg)\n",
    "        if (prob > threshold):\n",
    "            values.append(False)\n",
    "        else:\n",
    "            values.append(True)\n",
    "    return values\n",
    "\n",
    "#helper function to fill in the blanks for tags that have a confidence level less than the threshold\n",
    "def fill_blank_tags(predicted_tags, clf, X_test, series, threshold = 0.5):\n",
    "    boolean_array = tag_predicted(clf, X_test, series, threshold)\n",
    "    for i in range(len(predicted_tags)):\n",
    "        if (boolean_array[i] == True):\n",
    "            predicted_tags[i] = ''\n",
    "    return predicted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.0 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.19.0 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "model = pickle.load(open(\"model.pkl\", \"rb\")) #Model needs be named model.pkl\n",
    "output_dataset = pd.DataFrame(data = model.predict(list(processed_dataset['features_combined'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dataset = fill_blank_tags(output_dataset.iloc[:, 0].values, model, processed_dataset[\"features_combined\"], raw['Header'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hashtags(predicted_tags):\n",
    "    result = []\n",
    "    if (isinstance(predicted_tags, np.ndarray)):\n",
    "        for word in predicted_tags:\n",
    "            if word == '':\n",
    "                result.append('')\n",
    "            else:\n",
    "                result.append(\"#\"+word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dataset = add_hashtags(output_dataset)\n",
    "output_dataset = pd.DataFrame(add_hashtags(output_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['#date', '#date', '', '#affected', '#org', '#org', '', '#date',\n",
       "       '#date', '', '', '#affected', '#org', '', '', '#country', '', '',\n",
       "       '#date', '#date', '#affected', '', '#affected', '', '#status',\n",
       "       '#date', '#date', '', '#affected', '#affected', '#affected',\n",
       "       '#meta', '', '#date', '#date'], dtype=object)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dataset.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>budgetYear</th>\n",
       "      <th>description</th>\n",
       "      <th>amountUSD</th>\n",
       "      <th>srcOrganization</th>\n",
       "      <th>srcOrganizationTypes</th>\n",
       "      <th>srcLocations</th>\n",
       "      <th>srcUsageYearStart</th>\n",
       "      <th>srcUsageYearEnd</th>\n",
       "      <th>destPlan</th>\n",
       "      <th>...</th>\n",
       "      <th>firstReportedDate</th>\n",
       "      <th>decisionDate</th>\n",
       "      <th>keywords</th>\n",
       "      <th>originalAmount</th>\n",
       "      <th>originalCurrency</th>\n",
       "      <th>exchangeRate</th>\n",
       "      <th>id</th>\n",
       "      <th>refCode</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>updatedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#date</td>\n",
       "      <td>#date</td>\n",
       "      <td></td>\n",
       "      <td>#affected</td>\n",
       "      <td>#org</td>\n",
       "      <td>#org</td>\n",
       "      <td></td>\n",
       "      <td>#date</td>\n",
       "      <td>#date</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>#date</td>\n",
       "      <td>#date</td>\n",
       "      <td></td>\n",
       "      <td>#affected</td>\n",
       "      <td>#affected</td>\n",
       "      <td>#affected</td>\n",
       "      <td>#meta</td>\n",
       "      <td></td>\n",
       "      <td>#date</td>\n",
       "      <td>#date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#date</td>\n",
       "      <td>#date</td>\n",
       "      <td></td>\n",
       "      <td>#affected</td>\n",
       "      <td>#org</td>\n",
       "      <td>#org</td>\n",
       "      <td></td>\n",
       "      <td>#date</td>\n",
       "      <td>#date</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>#date</td>\n",
       "      <td>#date</td>\n",
       "      <td></td>\n",
       "      <td>#affected</td>\n",
       "      <td>#affected</td>\n",
       "      <td>#affected</td>\n",
       "      <td>#meta</td>\n",
       "      <td></td>\n",
       "      <td>#date</td>\n",
       "      <td>#date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#date</td>\n",
       "      <td>#date+year+budget</td>\n",
       "      <td>#description+notes</td>\n",
       "      <td>#value+funding+total+usd</td>\n",
       "      <td>#org+name+funder</td>\n",
       "      <td>#org+type+funder+list</td>\n",
       "      <td>#country+iso3+funder+list</td>\n",
       "      <td>#date+year+start+funder</td>\n",
       "      <td>#date+year+end+funder</td>\n",
       "      <td>#activity+appeal+name+impl</td>\n",
       "      <td>...</td>\n",
       "      <td>#date+reported</td>\n",
       "      <td>#date+decision</td>\n",
       "      <td>#description+keywords</td>\n",
       "      <td>#value+funding+total</td>\n",
       "      <td>#value+funding+total+currency</td>\n",
       "      <td>#financial+fx</td>\n",
       "      <td>#activity+id+fts_internal</td>\n",
       "      <td>#activity+code</td>\n",
       "      <td>#date+created</td>\n",
       "      <td>#date+updated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-03-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fall Army Worm / Lutte contre la chenille legi...</td>\n",
       "      <td>1000000</td>\n",
       "      <td>African Development Bank</td>\n",
       "      <td>Inter-governmental</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-03-14</td>\n",
       "      <td>2019-03-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>188251</td>\n",
       "      <td>OSRO/TOG/901/ADB</td>\n",
       "      <td>2019-03-15</td>\n",
       "      <td>2019-03-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Towards a Universal Access of Vulnerable Girls...</td>\n",
       "      <td>0</td>\n",
       "      <td>Education Above All Foundation</td>\n",
       "      <td>Private organization/foundation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-05-20</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>Multiyear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175161</td>\n",
       "      <td>EAA/EAC/CT/16/2016</td>\n",
       "      <td>2018-05-23</td>\n",
       "      <td>2018-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Towards a Universal Access of Vulnerable Girls...</td>\n",
       "      <td>183965</td>\n",
       "      <td>Education Above All Foundation</td>\n",
       "      <td>Private organization/foundation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-05-20</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>Multiyear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175165</td>\n",
       "      <td>EAA/EAC/CT/16/2016</td>\n",
       "      <td>2018-05-23</td>\n",
       "      <td>2018-05-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date         budgetYear  \\\n",
       "0       #date              #date   \n",
       "1       #date              #date   \n",
       "2       #date  #date+year+budget   \n",
       "3  2019-03-08                NaN   \n",
       "4  2017-01-31                NaN   \n",
       "5  2017-01-31                NaN   \n",
       "\n",
       "                                         description  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2                                 #description+notes   \n",
       "3  Fall Army Worm / Lutte contre la chenille legi...   \n",
       "4  Towards a Universal Access of Vulnerable Girls...   \n",
       "5  Towards a Universal Access of Vulnerable Girls...   \n",
       "\n",
       "                  amountUSD                 srcOrganization  \\\n",
       "0                 #affected                            #org   \n",
       "1                 #affected                            #org   \n",
       "2  #value+funding+total+usd                #org+name+funder   \n",
       "3                   1000000        African Development Bank   \n",
       "4                         0  Education Above All Foundation   \n",
       "5                    183965  Education Above All Foundation   \n",
       "\n",
       "              srcOrganizationTypes               srcLocations  \\\n",
       "0                             #org                              \n",
       "1                             #org                              \n",
       "2            #org+type+funder+list  #country+iso3+funder+list   \n",
       "3               Inter-governmental                        NaN   \n",
       "4  Private organization/foundation                        NaN   \n",
       "5  Private organization/foundation                        NaN   \n",
       "\n",
       "         srcUsageYearStart        srcUsageYearEnd                    destPlan  \\\n",
       "0                    #date                  #date                               \n",
       "1                    #date                  #date                               \n",
       "2  #date+year+start+funder  #date+year+end+funder  #activity+appeal+name+impl   \n",
       "3                     2019                   2019                         NaN   \n",
       "4                     2017                   2017                         NaN   \n",
       "5                     2017                   2017                         NaN   \n",
       "\n",
       "       ...       firstReportedDate    decisionDate               keywords  \\\n",
       "0      ...                   #date           #date                          \n",
       "1      ...                   #date           #date                          \n",
       "2      ...          #date+reported  #date+decision  #description+keywords   \n",
       "3      ...              2019-03-14      2019-03-08                    NaN   \n",
       "4      ...              2018-05-20      2017-01-31              Multiyear   \n",
       "5      ...              2018-05-20      2017-01-31              Multiyear   \n",
       "\n",
       "         originalAmount               originalCurrency   exchangeRate  \\\n",
       "0             #affected                      #affected      #affected   \n",
       "1             #affected                      #affected      #affected   \n",
       "2  #value+funding+total  #value+funding+total+currency  #financial+fx   \n",
       "3                   NaN                            USD            NaN   \n",
       "4                   NaN                            NaN            NaN   \n",
       "5                   NaN                            NaN            NaN   \n",
       "\n",
       "                          id             refCode      createdAt      updatedAt  \n",
       "0                      #meta                              #date          #date  \n",
       "1                      #meta                              #date          #date  \n",
       "2  #activity+id+fts_internal      #activity+code  #date+created  #date+updated  \n",
       "3                     188251    OSRO/TOG/901/ADB     2019-03-15     2019-03-18  \n",
       "4                     175161  EAA/EAC/CT/16/2016     2018-05-23     2018-05-23  \n",
       "5                     175165  EAA/EAC/CT/16/2016     2018-05-23     2018-05-23  \n",
       "\n",
       "[6 rows x 35 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dataset.loc[-1] = output_dataset.iloc[:, 0].values\n",
    "input_dataset.index = input_dataset.index + 1\n",
    "input_dataset = input_dataset.sort_index()\n",
    "input_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'na' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-ba2ac3d2b8f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moutput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Header'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_headers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# output_dataset.insert(loc=1, column='Original tag', value=np.array(input_dataset.iloc[0,:]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0moutput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Original tag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0moutput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Predicted tag\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moutput_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'na' is not defined"
     ]
    }
   ],
   "source": [
    "output_dataset.loc[empty_cols,0] = 'No Prediction. Column only had missing values'\n",
    "output_dataset.insert(loc=0, column='Header', value=input_headers)\n",
    "# output_dataset.insert(loc=1, column='Original tag', value=np.array(input_dataset.iloc[0,:]))\n",
    "output_dataset.insert(loc=1, column='Original tag', value=na)\n",
    "output_dataset.rename(index=str, columns={0: \"Predicted tag\"}, inplace=True)\n",
    "output_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "book = load_workbook('compare.xlsx')\n",
    "writer = pandas.ExcelWriter('compare.xlsx', engine='openpyxl')\n",
    "writer.book = book\n",
    "writer.sheets = {ws.title: ws for ws in book.worksheets}\n",
    "\n",
    "for sheetname in writer.sheets:\n",
    "    output_dataset.to_excel(writer,sheet_name=sheetname, startrow=writer.sheets[sheetname].max_row, index = False,header= False)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# @app.route('/', methods=['GET','POST'])\n",
    "# def upload_file():\n",
    "#     if request.method == 'POST':\n",
    "#         # check if the post request has the file part\n",
    "#         if 'file' not in request.files:\n",
    "#             flash('No file part')\n",
    "#             return redirect(request.url)\n",
    "#         file = request.files['file']\n",
    "        \n",
    "#         if file.filename == '':\n",
    "#             # flash('No selected file')\n",
    "#             return redirect(request.url)\n",
    "#         # file.save(os.getcwd())\n",
    "#         if file and allowed_file_csv(file.filename):\n",
    "#             filename = secure_filename(file.filename)\n",
    "#             input_dataset = pd.read_csv(file)\n",
    "                \n",
    "#         if file and allowed_file_json(file.filename):\n",
    "#             # filename = secure_filename(file.filename)\n",
    "#             input_dataset = pd.read_json(file)\n",
    "#             input_dataset = input_dataset.rename(columns=input_dataset.iloc[0]).drop(input_dataset.index[0])\n",
    "#                 # process the untagged dataset\n",
    "#         processed_dataset = preprocess(input_dataset, \n",
    "#             pd.DataFrame(columns=['Header','Data','Relative Column Position','Organization','Index']))\n",
    "#         model = pickle.load(open(\"model.pkl\", \"rb\")) #Model needs be named model.pkl, preferably using version 0.20.3\n",
    "#         output_dataset = pd.DataFrame(data = model.predict(list(processed_dataset['features_combined'])))\n",
    "#         resp = make_response(output_dataset.to_csv())\n",
    "#         resp.headers[\"Content-Disposition\"] = \"attachment; filename=export.csv\"\n",
    "#         resp.headers[\"Content-Type\"] = \"text/csv\"\n",
    "#         return resp\n",
    "        \n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    return \n",
    "<br>\n",
    "    <!doctype html><br>\n",
    "    <title>Upload new File</title><br>\n",
    "    <h1>Upload new File (only CSV and JSON files accepted)</h1><br>\n",
    "    <form method=post enctype=multipart/form-data><br>\n",
    "      <input type=file name=file><br>\n",
    "      <input type=submit value=Upload><br>\n",
    "    # <form method=post><br>\n",
    "    #   <input name=text><br>\n",
    "    #   <input type=submit><br>\n",
    "    </form><br>\n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"model.pkl\", \"rb\")) #Model needs be named model.pkl\n",
    "output_dataset = pd.DataFrame(data = model.predict(list(processed_dataset['features_combined'])))\n",
    "output_dataset.loc[empty_cols,0] = 'No Prediction. Column only had missing values'\n",
    "output_dataset.insert(loc=0, column='Header', value=input_headers)\n",
    "output_dataset.insert(loc=1, column='original tag', value=input_dataset.iloc[0,:].values)\n",
    "output_dataset.rename(index=str, columns={0: \"Predicted tag\"}, inplace=True)\n",
    "output_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#      app.run(debug=True)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
